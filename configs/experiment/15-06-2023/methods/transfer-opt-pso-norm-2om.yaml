# @package _global_
# TODO: Use best-performing config of prev. experiments in base_experiment
---
defaults:
  - base_experiment
  - override /method: cosil2
  - override /method/agent: sac
  - override /method/rewarder: env

method:
  # We perform learning over only two morphologies,
  # since we have a prefilled replay buffer
  replay_buffer_path: data/replay_buffers/merged/buffer_1686502257.pt
  pretrain: false
  pretrain_path: data/pretrained/pretrained_models_1686576083.pt
  num_episodes: 100
  episodes_per_morpho: 50
  morpho_warmup: 0
  start_steps: 0
  disc_warmup: 0
  co_adaptation:
    dist_optimizer: pso

  normalization_type: z_score
  normalization_mode: min
  normalization_gamma: 100.0
  normalization_beta: 0.0
  normalization_low_clip: null
  normalization_high_clip: null
  transfer: true
  optimized_demonstrator: true
  omega_init: 0.2

logger:
  group_name: "15-06-2023_methods"
  experiment_name: "transfer-opt-pso-2om"
  loggers: console,file,wandb
