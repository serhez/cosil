# @package _global_
# TODO: Use best-performing config of prev. experiments in base_halfcheetah_experiment
---
defaults:
  - base_halfcheetah_experiment
  - override /method: cosil
  - override /method/agent: sac
  - override /method/rewarder: env

method:
  # We perform learning over only two morphologies,
  # since we have a prefilled replay buffer
  replay_buffer_path: data/replay_buffers/merged/buffer_1686502257.pt
  pretrain: false
  pretrain_path: data/pretrained/pretrained_models_1686576083.pt
  num_episodes: 100
  episodes_per_morpho: 50
  morpho_warmup: 0
  start_steps: 0
  disc_warmup: 0
  co_adaptation:
    dist_optimizer: bo

  normalization_type: none
  transfer: true
  optimized_demonstrator: true
  omega_init: 0.5

logger:
  group_name: "15-06-2023_methods"
  experiment_name: "transfer-opt-bo-5om"
  loggers: console,file,wandb
